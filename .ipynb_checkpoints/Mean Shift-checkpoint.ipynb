{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Shift\n",
    "\n",
    "notes for this video series: https://www.youtube.com/watch?v=3ERPpzrDkVg&index=39&list=PLQVvvaa0QuDfKTOs3Keq_kaG2P55YRn5v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Video 39: Mean Shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import MeanShift, KMeans\n",
    "from sklearn import preprocessing, cross_validation\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://pythonprogramming.net/static/downloads/machine-learning-data/titanic.xls\n",
    "\n",
    "#Base on the code in K Means\n",
    "\n",
    "df = pd.read_excel('titanic.xls')\n",
    "\n",
    "original_df = pd.DataFrame.copy(df)  # this is new, make a copy of the original df\n",
    "df.drop(['body','name'], 1, inplace=True)\n",
    "df.fillna(0,inplace=True)\n",
    "\n",
    "def handle_non_numerical_data(df):\n",
    "    \n",
    "    # handling non-numerical data: must convert.\n",
    "    columns = df.columns.values\n",
    "\n",
    "    for column in columns:\n",
    "        text_digit_vals = {}\n",
    "        def convert_to_int(val):\n",
    "            return text_digit_vals[val]\n",
    "\n",
    "        #print(column,df[column].dtype)\n",
    "        if df[column].dtype != np.int64 and df[column].dtype != np.float64:\n",
    "            \n",
    "            column_contents = df[column].values.tolist()\n",
    "            #finding just the uniques\n",
    "            unique_elements = set(column_contents)\n",
    "            # great, found them. \n",
    "            x = 0\n",
    "            for unique in unique_elements:\n",
    "                if unique not in text_digit_vals:\n",
    "                    # creating dict that contains new\n",
    "                    # id per unique string\n",
    "                    text_digit_vals[unique] = x\n",
    "                    x+=1\n",
    "            # now we map the new \"id\" vlaue\n",
    "            # to replace the string. \n",
    "            df[column] = list(map(convert_to_int,df[column]))\n",
    "        \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=None, bin_seeding=False, cluster_all=True, min_bin_freq=1,\n",
       "     n_jobs=1, seeds=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = handle_non_numerical_data(df)\n",
    "df.drop(['ticket','home.dest'], 1, inplace=True)\n",
    "\n",
    "X = np.array(df.drop(['survived'], 1).astype(float))\n",
    "X = preprocessing.scale(X)\n",
    "y = np.array(df['survived'])\n",
    "\n",
    "clf = MeanShift()\n",
    "clf.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = clf.labels_\n",
    "cluster_centers = clf.cluster_centers_\n",
    "original_df['cluster_group'] = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JingXia/anaconda/lib/python3.6/site-packages/pandas/core/indexing.py:141: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    original_df['cluster_group'].iloc[i] = labels[i]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, label in enumerate(labels):\n",
    "        #original_df['cluster_group'].iloc[i] = label\n",
    "        original_df.loc.__setitem__(('cluster_group', i), label)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__setitem__() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-6fea853220d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0moriginal_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cluster_group'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __setitem__() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "for i in range(len(X)):\n",
    "    original_df.loc.__setitem__('cluster_group', i, (labels[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.373581847649919, 1: 0.19230769230769232, 2: 1.0, 3: 0.675, 4: 0.0}\n"
     ]
    }
   ],
   "source": [
    "n_clusters_ = len(np.unique(labels))\n",
    "survival_rates = {}\n",
    "for i in range(n_clusters_):\n",
    "    temp_df = original_df[ (original_df['cluster_group']==float(i)) ]\n",
    "    #print(temp_df.head())\n",
    "\n",
    "    survival_cluster = temp_df[  (temp_df['survived'] == 1) ]\n",
    "\n",
    "    survival_rate = len(survival_cluster) / len(temp_df)\n",
    "    #print(i,survival_rate)\n",
    "    survival_rates[i] = survival_rate\n",
    "    \n",
    "print(survival_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-d52546e17ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0msurvival_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'survived'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0msurvival_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msurvival_cluster\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;31m#print(i,survival_rate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msurvival_rates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msurvival_rate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "n_clusters_ = len(np.unique(labels))\n",
    "survival_rates = {}\n",
    "for i in range(n_clusters_):\n",
    "    temp_df = original_df[ (original_df['cluster_group']==float(i)) ]\n",
    "    #print(temp_df.head())\n",
    "\n",
    "    survival_cluster = temp_df[  (temp_df['survived'] == 1) ]\n",
    "\n",
    "    survival_rate = len(survival_cluster) / len(temp_df)\n",
    "    #print(i,survival_rate)\n",
    "    survival_rates[i] = survival_rate\n",
    "    \n",
    "print(survival_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
